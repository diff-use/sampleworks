import argparse
from pathlib import Path

import numpy as np
from biotite.structure import AtomArray, AtomArrayStack
from loguru import logger
from sklearn.metrics import silhouette_samples

from sampleworks.eval.constants import OCCUPANCY_LEVELS
from sampleworks.eval.eval_dataclasses import ProteinConfig
from sampleworks.eval.grid_search_eval_utils import scan_grid_search_results, parse_args
from sampleworks.eval.structure_utils import get_reference_structure_coords, \
    get_reference_atomarraystack
from sampleworks.metrics.lddt import AllAtomLDDT
from sampleworks.utils.atom_array_utils import filter_to_common_atoms


def compute_cross_lddts(
        ref_atom_array_stack: AtomArrayStack,
        pred_atom_array_stack: AtomArrayStack,
        selection: str = "all"
) -> np.ndarray:
    """
    Compute the LDDTs between each set of coordinates in ref_atom_array_stack and each
    in pred_atom_array_stack, considering only atoms that match the given selection.

    ref_atom_array_stack: AtomArrayStack containing reference coordinates (probably an RCSB entry,
        where each structure corresponds to a separate altloc)

    pred_atom_array_stack: AtomArrayStack containing predicted coordinates (probably generated by
        a structure prediction model, where each structure corresponds to a separate altloc)

    NOTE: this method DOES NOT select altlocs, you must do that yourself.

    Returns:
        np.ndarray: A 2D array of shape (len(ref_atom_array_stack), len(pred_atom_array_stack))
            containing the LDDTs for each pair of coordinates. LDDTs are computed using
            sampleworks.metrics.lddt.AllAtomLDDT's compute method. The LDDT score for each pair is
            the average over the 'residue_lddt_scores' output from compute().
    """
    n_ref = ref_atom_array_stack.stack_depth()
    n_pred = pred_atom_array_stack.stack_depth()

    # Initialize the result matrix
    lddt_matrix = np.zeros((n_ref, n_pred))

    # Create AllAtomLDDT metric instance
    lddt_metric = AllAtomLDDT()

    # Filter to common atoms once (they should be the same across all models in the stacks)
    ref_filtered, pred_filtered = filter_to_common_atoms(
        ref_atom_array_stack, pred_atom_array_stack
    )

    # Iterate over all pairs of reference and predicted structures
    for i in range(n_ref):
        for j in range(n_pred):
            # Extract individual AtomArrays for this pair
            ref_single: AtomArray = ref_filtered[i]
            pred_single: AtomArray = pred_filtered[j]

            # Compute LDDT using AllAtomLDDT
            # Pass selection parameter if not "all"
            if selection == "all":
                result = lddt_metric.compute(pred_single, ref_single, selection=None)
            else:
                result = lddt_metric.compute(pred_single, ref_single, selection=selection)

            # Extract residue-level LDDT scores
            residue_lddt_scores = result["residue_lddt_scores"]

            # Compute average over all residue-level LDDT scores
            # Each residue has a list of scores (one per model, but we're computing on single models)
            all_scores = []
            for residue_scores_list in residue_lddt_scores.values():
                # residue_scores_list is a list, typically with one value for single model comparison
                all_scores.extend(residue_scores_list)

            # Calculate the mean LDDT score
            if all_scores:
                lddt_matrix[i, j] = np.mean(all_scores)
            else:
                # If no scores computed (e.g., no residues match selection), set to NaN
                lddt_matrix[i, j] = np.nan

    return lddt_matrix


def nn_lddt_clustering(
        ref_atom_array_stack: AtomArrayStack,
        pred_atom_array_stack: AtomArrayStack,
        selection: str = "all"
):
    """
    ref_atom_array_stack: AtomArrayStack containing reference coordinates (probably an RCSB entry,
        where each structure corresponds to a separate altloc)

    pred_atom_array_stack: AtomArrayStack containing predicted coordinates (probably generated by
        a structure prediction model, where each structure corresponds to a separate altloc)

    NOTE: this method DOES NOT select altlocs, you must do that yourself.

    This method assigns a mapping from each predicted structure to the closest reference structure,
    based on the LDDT score. It then computes a silhouette score assuming that mapping as a clustering.
    It returns the average silhouette score for the clustering, a sort-of silhouette score assuming
    the cluster centers are the true (reference) structures, and a list of the occupancies of the
    clusters.

    Returns:
        A dictionary:
        {"avg_silhouette": float, "avg_silhouette_to_ref": float, "occupancies": list[int]}
    """
    # First compute the self-LDDT matrix between all structures in the predicted stack
    self_lddt_matrix = compute_cross_lddts(pred_atom_array_stack, pred_atom_array_stack, selection)

    # Second, compute the cross-LDDT matrix between all structures in the predicted stack and
    # all structures in the reference stack
    cross_lddt_matrix = compute_cross_lddts(pred_atom_array_stack, ref_atom_array_stack, selection)

    # Assign each predicted structure to the closest reference structure based on LDDT score (i.e.,
    # the reference structure with the highest LDDT score is assigned to the predicted structure)
    closest_ref_indices = np.argmax(cross_lddt_matrix, axis=0)

    # Compute the silhouette score assuming the nearest-reference neighbor clustering.
    ssamples = silhouette_samples(1 - self_lddt_matrix, closest_ref_indices, metric="precomputed")
    sscore = float(np.mean(ssamples))

    # Compute the occupancy of each cluster based on the number of structures in the cluster
    cluster_sizes = np.bincount(closest_ref_indices)
    occupancy_levels = cluster_sizes / cluster_sizes.sum()

    # compute something like a silhouette score, comparing each point's distance to it's assigned
    # cluster center (the reference structure) to it's next-nearest reference structure.
    #  First, partition the "lddt distance" matrix; this ensures the top two values are the
    #  smallest and second-smallest distances, respectively.
    partitioned_distances = np.partition(1 - cross_lddt_matrix, 2, axis=0)

    # for each cluster, compute something like a silhouette score
    avg_silhouette_to_ref = np.mean(1 - partitioned_distances[0] / partitioned_distances[1])

    return {
        "avg_silhouette": sscore,
        "occupancies": occupancy_levels,
        "avg_silhouette_to_ref": avg_silhouette_to_ref,
        "self_lddt_matrix": self_lddt_matrix,
        "cross_lddt_matrix": cross_lddt_matrix,
        "closest_ref_indices": closest_ref_indices
    }


def main(args: argparse.Namespace):
    workspace_root = Path(args.workspace_root)
    grid_search_dir = workspace_root / "grid_search_results"  # TODO make more general

    # Protein configurations: base map paths, structure selections, and resolutions
    protein_inputs_dir = args.grid_search_inputs_path or workspace_root
    protein_configs = ProteinConfig.from_csv(protein_inputs_dir, args.protein_configs_csv)

    logger.info(f"Grid search directory: {grid_search_dir}")
    logger.info(f"Proteins configured: {list(protein_configs.keys())}")

    # Scan for experiments (look for refined.cif files)
    all_experiments = scan_grid_search_results(grid_search_dir)
    logger.info(f"Found {len(all_experiments)} experiments with refined.cif files")

    if all_experiments:
        all_experiments.summarize()  # Prints some summary stats, e.g. number of unique proteins

    logger.info("Pre-loading reference structures for each protein for coordinate extraction")
    reference_atom_arrays = {}
    for protein_key, protein_config in protein_configs.items():
        # TODO: should the reference occupancy should be specified in the config?
        for occ in OCCUPANCY_LEVELS:
            reference_proteins = get_reference_atomarraystack(protein_config, occ)
            if reference_proteins is not None:
                reference_atom_arrays[(protein_key, occ)] = reference_proteins


if __name__ == "__main__":
    args = parse_args("Evaluate LDDT on grid search results.")
    main(args)
